{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926bae46",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e038ddf1",
   "metadata": {},
   "source": [
    "Suppress TensorFlow warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec05d94-4361-49d2-b680-ce41d0376299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from:\n",
    "# https://weepingfish.github.io/2020/07/22/0722-suppress-tensorflow-warnings/\n",
    "\n",
    "# Filter tensorflow version warnings\n",
    "import os\n",
    "\n",
    "# https://stackoverflow.com/questions/40426502/is-there-a-way-to-suppress-the-messages-tensorflow-prints/40426709\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # or any {'0', '1', '2'}\n",
    "import warnings\n",
    "\n",
    "# https://stackoverflow.com/questions/15777951/how-to-suppress-pandas-future-warning\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=Warning)\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel(\"INFO\")\n",
    "tf.autograph.set_verbosity(0)\n",
    "import logging\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae636ae-24d1-4523-9997-696731318a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4f0a2",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8238055-08bf-44e1-8f3b-98e7768f1603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change batch size accordingly in case of OOM.\n",
    "# Change the image size to 384 wheb evaluation's done on 224.\n",
    "BATCH_SIZE = 256\n",
    "IMAGE_SIZE = 224\n",
    "TF_MODEL_ROOT = \"gs://swin-tf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea42076a",
   "metadata": {},
   "source": [
    "## Swin models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a7e46e-31b2-48b9-9a57-2873fe27397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = tf.io.gfile.listdir(TF_MODEL_ROOT)\n",
    "model_paths = [p for p in model_paths if str(IMAGE_SIZE) in p and \"fe\" not in p and \"22k\" not in p]\n",
    "print(model_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c39720",
   "metadata": {},
   "source": [
    "## Image loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b066a571",
   "metadata": {},
   "source": [
    "To have an apples-to-apples comparison with the original PyTorch models for evaluation, it's important to ensure we use the same transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf8eb2e-de82-48af-9292-c4917c237fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations from:\n",
    "# (1) https://github.com/microsoft/Swin-Transformer\n",
    "# (2) https://github.com/microsoft/Swin-Transformer/tree/main/data\n",
    "\n",
    "if IMAGE_SIZE == 224:\n",
    "    size = int((256 / 224) * IMAGE_SIZE)\n",
    "    transform_chain = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(size, interpolation=3),\n",
    "            transforms.CenterCrop(IMAGE_SIZE),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    transform_chain = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE), interpolation=3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae139c-786b-47b3-9840-655c624f86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(\"val\", transform=transform_chain)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=6)\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "print(batch[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7e8e68",
   "metadata": {},
   "source": [
    "## Run evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a3da22-a60f-48b8-a0b0-02e54b2d012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_url):\n",
    "    model = keras.models.load_model(model_url)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8eabf-df6d-4ee5-900c-48b8761329ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied and modified from:\n",
    "# https://github.com/sebastian-sz/resnet-rs-keras/blob/main/imagenet_evaluation/main.py\n",
    "\n",
    "log_file = f\"swin_{IMAGE_SIZE}_in1k.csv\"\n",
    "\n",
    "if not os.path.exists(log_file):\n",
    "    with open(log_file, 'w') as f:\n",
    "        f.write(\n",
    "            'model_name,top1_acc(%),top5_acc(%)\\n'\n",
    "        )\n",
    "\n",
    "for path in model_paths:\n",
    "    print(f\"Evaluating {path}.\")\n",
    "    model = get_model(f\"{TF_MODEL_ROOT}/{path.strip('/')}\")\n",
    "\n",
    "    top1 = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=1, name=\"top1\")\n",
    "    top5 = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name=\"top5\")\n",
    "    progbar = tf.keras.utils.Progbar(target=len(dataset) // BATCH_SIZE)\n",
    "\n",
    "    for idx, (images, y_true) in enumerate(dataloader):\n",
    "        images = images.numpy().transpose(0, 2, 3, 1)\n",
    "        y_true = y_true.numpy()\n",
    "        y_pred = model.predict(images)\n",
    "\n",
    "        top1.update_state(y_true=y_true, y_pred=y_pred)\n",
    "        top5.update_state(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "        progbar.update(\n",
    "            idx, [(\"top1\", top1.result().numpy()), (\"top5\", top5.result().numpy())]\n",
    "        )\n",
    "\n",
    "    print()\n",
    "    print(f\"TOP1: {top1.result().numpy()}.  TOP5: {top5.result().numpy()}\")\n",
    "    \n",
    "    top_1 = top1.result().numpy() * 100.\n",
    "    top_5 = top5.result().numpy() * 100.\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(\"%s,%0.3f,%0.3f\\n\" % (path, top_1, top_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c845cdcb-1036-43e2-93df-4d47cce020ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo shutdown now"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
