{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40180afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ef790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from swins import SwinTransformer\n",
    "from swins.layers import *\n",
    "from swins.blocks import *\n",
    "from utils import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d2ec87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = dict(\n",
    "    patch_size=4,\n",
    "    window_size=7,\n",
    "    embed_dim=96,\n",
    "    depths=(2, 2, 6, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59542c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-08 18:23:21.505079: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swin TF model created.\n"
     ]
    }
   ],
   "source": [
    "swin_tiny_patch4_window7_224_tf = SwinTransformer(\n",
    "    name=\"swin_tiny_patch4_window7_224\", **cfg\n",
    ")\n",
    "random_tensor = tf.random.normal((2, 224, 224, 3))\n",
    "outputs = swin_tiny_patch4_window7_224_tf(random_tensor, training=False)\n",
    "print(\"Swin TF model created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29d6661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sayakpaul/.local/bin/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swin PT model created.\n",
      "Number of parameters:\n",
      "28.288354\n"
     ]
    }
   ],
   "source": [
    "swin_tiny_patch4_window7_224_pt = timm.create_model(\n",
    "    model_name=\"swin_tiny_patch4_window7_224\", pretrained=True\n",
    ")\n",
    "print(\"Swin PT model created.\")\n",
    "print(\"Number of parameters:\")\n",
    "num_params = sum(p.numel() for p in swin_tiny_patch4_window7_224_pt.parameters())\n",
    "print(num_params / 1e6)\n",
    "\n",
    "assert swin_tiny_patch4_window7_224_tf.count_params() == num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50ee5556",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = swin_tiny_patch4_window7_224_pt.state_dict()\n",
    "np_state_dict = {k: state_dict[k].numpy() for k in state_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbbc3080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection.\n",
    "swin_tiny_patch4_window7_224_tf.projection.layers[0] = helpers.modify_tf_block(\n",
    "    swin_tiny_patch4_window7_224_tf.projection.layers[0],\n",
    "    np_state_dict[\"patch_embed.proj.weight\"],\n",
    "    np_state_dict[\"patch_embed.proj.bias\"],\n",
    ")\n",
    "swin_tiny_patch4_window7_224_tf.projection.layers[2] = helpers.modify_tf_block(\n",
    "    swin_tiny_patch4_window7_224_tf.projection.layers[2],\n",
    "    np_state_dict[\"patch_embed.norm.weight\"],\n",
    "    np_state_dict[\"patch_embed.norm.bias\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e80ad36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer norm layers.\n",
    "ln_idx = -2\n",
    "swin_tiny_patch4_window7_224_tf.layers[ln_idx] = helpers.modify_tf_block(\n",
    "    swin_tiny_patch4_window7_224_tf.layers[ln_idx],\n",
    "    np_state_dict[\"norm.weight\"],\n",
    "    np_state_dict[\"norm.bias\"],\n",
    ")\n",
    "\n",
    "# Head layers.\n",
    "head_layer = swin_tiny_patch4_window7_224_tf.get_layer(\"classification_head\")\n",
    "swin_tiny_patch4_window7_224_tf.layers[-1] = helpers.modify_tf_block(\n",
    "    head_layer,\n",
    "    np_state_dict[\"head.weight\"],\n",
    "    np_state_dict[\"head.bias\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03ba0496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['layers.0.blocks.0.norm1.weight',\n",
       " 'layers.0.blocks.0.norm1.bias',\n",
       " 'layers.0.blocks.0.attn.relative_position_bias_table',\n",
       " 'layers.0.blocks.0.attn.relative_position_index',\n",
       " 'layers.0.blocks.0.attn.qkv.weight',\n",
       " 'layers.0.blocks.0.attn.qkv.bias',\n",
       " 'layers.0.blocks.0.attn.proj.weight',\n",
       " 'layers.0.blocks.0.attn.proj.bias',\n",
       " 'layers.0.blocks.0.norm2.weight',\n",
       " 'layers.0.blocks.0.norm2.bias',\n",
       " 'layers.0.blocks.0.mlp.fc1.weight',\n",
       " 'layers.0.blocks.0.mlp.fc1.bias',\n",
       " 'layers.0.blocks.0.mlp.fc2.weight',\n",
       " 'layers.0.blocks.0.mlp.fc2.bias',\n",
       " 'layers.0.blocks.1.attn_mask',\n",
       " 'layers.0.blocks.1.norm1.weight',\n",
       " 'layers.0.blocks.1.norm1.bias',\n",
       " 'layers.0.blocks.1.attn.relative_position_bias_table',\n",
       " 'layers.0.blocks.1.attn.relative_position_index',\n",
       " 'layers.0.blocks.1.attn.qkv.weight',\n",
       " 'layers.0.blocks.1.attn.qkv.bias',\n",
       " 'layers.0.blocks.1.attn.proj.weight',\n",
       " 'layers.0.blocks.1.attn.proj.bias',\n",
       " 'layers.0.blocks.1.norm2.weight',\n",
       " 'layers.0.blocks.1.norm2.bias',\n",
       " 'layers.0.blocks.1.mlp.fc1.weight',\n",
       " 'layers.0.blocks.1.mlp.fc1.bias',\n",
       " 'layers.0.blocks.1.mlp.fc2.weight',\n",
       " 'layers.0.blocks.1.mlp.fc2.bias',\n",
       " 'layers.0.downsample.reduction.weight',\n",
       " 'layers.0.downsample.norm.weight',\n",
       " 'layers.0.downsample.norm.bias']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: \"layers.0\" in x, np_state_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c7af809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_swin_blocks(pt_weights_prefix, tf_block):\n",
    "    # Patch merging.\n",
    "    for layer in tf_block:\n",
    "        if isinstance(layer, PatchMerging):\n",
    "            patch_merging_idx = f\"{pt_weights_prefix}.downsample\"\n",
    "\n",
    "            layer.reduction = helpers.modify_tf_block(\n",
    "                layer.reduction,\n",
    "                np_state_dict[f\"{patch_merging_idx}.reduction.weight\"],\n",
    "            )\n",
    "            layer.norm = helpers.modify_tf_block(\n",
    "                layer.norm,\n",
    "                np_state_dict[f\"{patch_merging_idx}.norm.weight\"],\n",
    "                np_state_dict[f\"{patch_merging_idx}.norm.bias\"],\n",
    "            )\n",
    "\n",
    "    # Swin layers.\n",
    "    common_prefix = f\"{pt_weights_prefix}.blocks\"\n",
    "    block_idx = 0\n",
    "\n",
    "    for outer_layer in tf_block:\n",
    "\n",
    "        layernorm_idx = 1\n",
    "        mlp_layer_idx = 1\n",
    "\n",
    "        if isinstance(outer_layer, SwinTransformerBlock):\n",
    "            for inner_layer in outer_layer.layers:\n",
    "\n",
    "                # Layer norm.\n",
    "                if isinstance(inner_layer, tf.keras.layers.LayerNormalization):\n",
    "                    layer_norm_prefix = (\n",
    "                        f\"{common_prefix}.{block_idx}.norm{layernorm_idx}\"\n",
    "                    )\n",
    "                    inner_layer.gamma.assign(\n",
    "                        tf.Variable(np_state_dict[f\"{layer_norm_prefix}.weight\"])\n",
    "                    )\n",
    "                    inner_layer.beta.assign(\n",
    "                        tf.Variable(np_state_dict[f\"{layer_norm_prefix}.bias\"])\n",
    "                    )\n",
    "                    layernorm_idx += 1\n",
    "\n",
    "                # Windown attention.\n",
    "                elif isinstance(inner_layer, WindowAttention):\n",
    "                    attn_prefix = f\"{common_prefix}.{block_idx}.attn\"\n",
    "\n",
    "                    # Relative position.\n",
    "                    inner_layer.relative_position_bias_table = helpers.modify_tf_block(\n",
    "                        inner_layer.relative_position_bias_table,\n",
    "                        np_state_dict[f\"{attn_prefix}.relative_position_bias_table\"],\n",
    "                    )\n",
    "                    inner_layer.relative_position_index = helpers.modify_tf_block(\n",
    "                        inner_layer.relative_position_index,\n",
    "                        np_state_dict[f\"{attn_prefix}.relative_position_index\"],\n",
    "                    )\n",
    "\n",
    "                    # QKV.\n",
    "                    inner_layer.qkv = helpers.modify_tf_block(\n",
    "                        inner_layer.qkv,\n",
    "                        np_state_dict[f\"{attn_prefix}.qkv.weight\"],\n",
    "                        np_state_dict[f\"{attn_prefix}.qkv.bias\"],\n",
    "                    )\n",
    "\n",
    "                    # Projection.\n",
    "                    inner_layer.proj = helpers.modify_tf_block(\n",
    "                        inner_layer.proj,\n",
    "                        np_state_dict[f\"{attn_prefix}.proj.weight\"],\n",
    "                        np_state_dict[f\"{attn_prefix}.proj.bias\"],\n",
    "                    )\n",
    "\n",
    "                # MLP.\n",
    "                elif isinstance(inner_layer, tf.keras.Model):\n",
    "                    mlp_prefix = f\"{common_prefix}.{block_idx}.mlp\"\n",
    "                    for mlp_layer in inner_layer.layers:\n",
    "                        if isinstance(mlp_layer, tf.keras.layers.Dense):\n",
    "                            mlp_layer = helpers.modify_tf_block(\n",
    "                                mlp_layer,\n",
    "                                np_state_dict[f\"{mlp_prefix}.fc{mlp_layer_idx}.weight\"],\n",
    "                                np_state_dict[f\"{mlp_prefix}.fc{mlp_layer_idx}.bias\"],\n",
    "                            )\n",
    "                            mlp_layer_idx += 1\n",
    "\n",
    "            block_idx += 1\n",
    "    return tf_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d947e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = modify_swin_blocks(\n",
    "    \"layers.0\",\n",
    "    swin_tiny_patch4_window7_224_tf.layers[2].layers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdb9c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_block = swin_tiny_patch4_window7_224_tf.layers[2].layers\n",
    "pt_weights_prefix = \"layers.0\"\n",
    "\n",
    "# Patch merging.\n",
    "for layer in tf_block:\n",
    "    if isinstance(layer, PatchMerging):\n",
    "        patch_merging_idx = f\"{pt_weights_prefix}.downsample\"\n",
    "        np.testing.assert_allclose(\n",
    "            np_state_dict[f\"{patch_merging_idx}.reduction.weight\"].transpose(),\n",
    "            layer.reduction.kernel.numpy(),\n",
    "        )\n",
    "        np.testing.assert_allclose(\n",
    "            np_state_dict[f\"{patch_merging_idx}.norm.weight\"], layer.norm.gamma.numpy()\n",
    "        )\n",
    "        np.testing.assert_allclose(\n",
    "            np_state_dict[f\"{patch_merging_idx}.norm.bias\"], layer.norm.beta.numpy()\n",
    "        )\n",
    "\n",
    "# Swin layers.\n",
    "common_prefix = f\"{pt_weights_prefix}.blocks\"\n",
    "block_idx = 0\n",
    "\n",
    "for outer_layer in tf_block:\n",
    "\n",
    "    layernorm_idx = 1\n",
    "    mlp_layer_idx = 1\n",
    "\n",
    "    if isinstance(outer_layer, SwinTransformerBlock):\n",
    "        for inner_layer in outer_layer.layers:\n",
    "\n",
    "            # Layer norm.\n",
    "            if isinstance(inner_layer, tf.keras.layers.LayerNormalization):\n",
    "                layer_norm_prefix = f\"{common_prefix}.{block_idx}.norm{layernorm_idx}\"\n",
    "                np.testing.assert_allclose(\n",
    "                    np_state_dict[f\"{layer_norm_prefix}.weight\"],\n",
    "                    inner_layer.gamma.numpy(),\n",
    "                )\n",
    "                np.testing.assert_allclose(\n",
    "                    np_state_dict[f\"{layer_norm_prefix}.bias\"], inner_layer.beta.numpy()\n",
    "                )\n",
    "                layernorm_idx += 1\n",
    "\n",
    "            # Windown attention.\n",
    "            elif isinstance(inner_layer, WindowAttention):\n",
    "                attn_prefix = f\"{common_prefix}.{block_idx}.attn\"\n",
    "\n",
    "                # Relative position.\n",
    "                np.testing.assert_allclose(\n",
    "                    np_state_dict[f\"{attn_prefix}.relative_position_bias_table\"],\n",
    "                    inner_layer.relative_position_bias_table.numpy(),\n",
    "                )\n",
    "\n",
    "                np.testing.assert_allclose(\n",
    "                    np_state_dict[f\"{attn_prefix}.relative_position_index\"],\n",
    "                    inner_layer.relative_position_index.numpy(),\n",
    "                )\n",
    "\n",
    "                # QKV.\n",
    "                np.testing.assert_allclose(\n",
    "                    np_state_dict[f\"{attn_prefix}.qkv.weight\"].transpose(),\n",
    "                    inner_layer.qkv.kernel.numpy(),\n",
    "                )\n",
    "                np.testing.assert_allclose(\n",
    "                    np_state_dict[f\"{attn_prefix}.qkv.bias\"],\n",
    "                    inner_layer.qkv.bias.numpy(),\n",
    "                )\n",
    "\n",
    "                # Projection.\n",
    "                np.testing.assert_allclose(\n",
    "                    np_state_dict[f\"{attn_prefix}.proj.weight\"].transpose(),\n",
    "                    inner_layer.proj.kernel.numpy(),\n",
    "                )\n",
    "                np.testing.assert_allclose(\n",
    "                    np_state_dict[f\"{attn_prefix}.proj.bias\"],\n",
    "                    inner_layer.proj.bias.numpy(),\n",
    "                )\n",
    "\n",
    "            # MLP.\n",
    "            elif isinstance(inner_layer, tf.keras.Model):\n",
    "                mlp_prefix = f\"{common_prefix}.{block_idx}.mlp\"\n",
    "                for mlp_layer in inner_layer.layers:\n",
    "                    if isinstance(mlp_layer, tf.keras.layers.Dense):\n",
    "                        np.testing.assert_allclose(\n",
    "                            np_state_dict[\n",
    "                                f\"{mlp_prefix}.fc{mlp_layer_idx}.weight\"\n",
    "                            ].transpose(),\n",
    "                            mlp_layer.kernel.numpy(),\n",
    "                        )\n",
    "                        np.testing.assert_allclose(\n",
    "                            np_state_dict[f\"{mlp_prefix}.fc{mlp_layer_idx}.bias\"],\n",
    "                            mlp_layer.bias.numpy(),\n",
    "                        )\n",
    "\n",
    "                        mlp_layer_idx += 1\n",
    "\n",
    "        block_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9743e538",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cfg[\"depths\"])):\n",
    "    _ = modify_swin_blocks(\n",
    "        f\"layers.{i}\",\n",
    "        swin_tiny_patch4_window7_224_tf.layers[i+2].layers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71d471b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "672266c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_resolution = 224\n",
    "\n",
    "crop_layer = tf.keras.layers.CenterCrop(input_resolution, input_resolution)\n",
    "norm_layer = tf.keras.layers.Normalization(\n",
    "    mean=[0.485 * 255, 0.456 * 255, 0.406 * 255],\n",
    "    variance=[(0.229 * 255) ** 2, (0.224 * 255) ** 2, (0.225 * 255) ** 2],\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess_image(image, size=input_resolution):\n",
    "    image = np.array(image)\n",
    "    image_resized = tf.expand_dims(image, 0)\n",
    "    resize_size = int((256 / 224) * size)\n",
    "    image_resized = tf.image.resize(\n",
    "        image_resized, (resize_size, resize_size), method=\"bicubic\"\n",
    "    )\n",
    "    image_resized = crop_layer(image_resized)\n",
    "    return norm_layer(image_resized).numpy()\n",
    "\n",
    "\n",
    "def load_image_from_url(url):\n",
    "    # Credit: Willi Gierke\n",
    "    response = requests.get(url)\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "    return image, preprocessed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3f28a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://storage.googleapis.com/bit_models/ilsvrc2012_wordnet_lemmas.txt -O ilsvrc2012_wordnet_lemmas.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43627c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ilsvrc2012_wordnet_lemmas.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "imagenet_int_to_str = [line.rstrip() for line in lines]\n",
    "\n",
    "img_url = \"https://p0.pikrepo.com/preview/853/907/close-up-photo-of-gray-elephant.jpg\"\n",
    "image, preprocessed_image = load_image_from_url(img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7adfa5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = swin_tiny_patch4_window7_224_tf.predict(preprocessed_image)\n",
    "logits = predictions[0]\n",
    "predicted_label = imagenet_int_to_str[int(np.argmax(logits))]\n",
    "expected_label = \"Indian_elephant, Elephas_maximus\"\n",
    "assert (\n",
    "    predicted_label == expected_label\n",
    "), f\"Expected {expected_label} but was {predicted_label}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cb44e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['swin_stage_0', 'swin_stage_1', 'swin_stage_2', 'swin_stage_3'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_attn_scores = swin_tiny_patch4_window7_224_tf.get_attention_scores(\n",
    "    preprocessed_image\n",
    ")\n",
    "all_attn_scores.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a1244ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['swin_block_0', 'swin_block_1'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_attn_scores[\"swin_stage_3\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6d1b5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 24, 49, 49])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_attn_scores[\"swin_stage_3\"][\"swin_block_0\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f69a8d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-08 18:23:42.809960: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as layer_normalization_5_layer_call_fn, layer_normalization_5_layer_call_and_return_conditional_losses, dense_4_layer_call_fn, dense_4_layer_call_and_return_conditional_losses, layer_normalization_10_layer_call_fn while saving (showing 5 of 108). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://swin-tf/swin_tiny_patch4_window7_224_tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://swin-tf/swin_tiny_patch4_window7_224_tf/assets\n"
     ]
    }
   ],
   "source": [
    "swin_tiny_patch4_window7_224_tf.save(\"gs://swin-tf/swin_tiny_patch4_window7_224_tf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
